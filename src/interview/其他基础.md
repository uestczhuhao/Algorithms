### 读扩散和写扩散
#### 写扩散(Push)
该方式为每个用户维护一个订阅列表，记录该用户订阅的消息索引（一般为消息ID、类型、发表时间等一些元数据）。每当用户发布消息时，都会去更新其follower的订阅列表。
优点：读很轻。初始化时仅需要读取自己的inbox即可。
缺点：写很重。每发布一个消息，会导致大量的写操作。
注：一般来说，用户发布消息，并不会更新所有followers的订阅列表，仅更新在线followers即可。

#### 读扩散(Pull)
该方式为每个用户维护一个发送列表，记录该用户所有发表过的消息索引。
优点：写很轻，节省空间。用户每发布一条消息，仅需更新自己的outbox。
缺点：读操作很重，计算量大。假设你收听了1k用户，则初始化时，需要从1k个用户的outbox拉取消息，然后计算获得最新的n条消息。

#### 混合模式(Push+Pull)
该方式既为读写扩散的结合，根据用户followers的数量来决定是读扩散还是写扩散。例如followers大于1k的，则使用读扩散，否则使用写扩散。

### TPS、RPS和QPS的区别
- TPS：Transactions Per Second（每秒传输的事物处理个数），即服务器每秒处理的事务数。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。
  - 客户机在发送请时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。
- QPS：Queries Per Second意思是“每秒查询率”，是一台服务器每秒能够响应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。
- 区别：QPS只考虑查询操作，而TPS考虑所有的事务操作
- 如果是容量场景，假设n个接口都是查询接口，且这个接口内部不会再去请求其它接口，qps=n*tps
- RPS 代表吞吐率，即 Requests Per Second，指的是某个并发用户数下单位时间内处理的请求数，等效于QPS

### 存储IP地址，用什么数据类型比较好？
- IPV4：无符号整数，需要转换成32位整数，其中每个八位代表一个 IP 地址段
  - 有如下的好处： 
    - 节省空间，不管是数据存储空间，还是索引存储空间
    - 便于使用范围查询（BETWEEN...AND），且效率更高
  - 缺点
    - 不便于阅读
    - 需要手动转换
- IPv6：
  - varchar(39)
    - IPv6地址通常写成八组，每组四个十六进制数字，每组由冒号(:)分隔。
    - 2001:0db8:0000:0000:0000:ff00:0042:8329 
    - 那最多39个字符
  - varbinary
    - 和IPV4用int存放一样

### 微服务传输traceId，放在哪里？
- 一般放在HTTP的请求头里，X-Trace-Id

### 怎么预防CSRF？
用csrf防止cookie被盗用，


### 给定m个不重复字符[a,b,c]，以及一个长度为n的字符串，问是否能在这个字符串中找到一个长度为m的连续子串，要求子串由m个字符组成，顺序不要求
- TODO

## 操作系统
- 1000个并发，10台机器，每个4核，设计线程池大小
  - 1000 个并发线程交给 10 台机器去处理，那么 1 台机器就是承担 100 个并发请求。（考虑是峰值，还是均值）
    - 平均分配的话，要考虑负载均衡
    - 以nginx为例
      -（加权）轮询负载均衡 
    - 随机负载均衡 
    - 最少连接数负载均衡 
    - 最小响应时间负载均衡 
    - ip_hash负载均衡 
    - url_hash负载均衡
  - 如果是 CPU 密集型的任务，我们应该尽量的减少上下文切换，所以核心线程数可以设置为 5，队列的长度可以设置为 100，最大线程数保持和核心线程数一致。
  - 如果是 IO 密集型的任务，我们可以适当的多分配一点核心线程数，更好的利用 CPU，所以核心线程数可以设置为 8，队列长度还是 100，最大线程池设置为 10。
  - 进行系统压测，通过压测结果的对比，从而确定最合适的设置
  - 线程池的参数应该是随着系统流量的变化而变化
- 如果这时由于搞促销活动，系统流量翻了好倍，那你说这种情况下最先出现性能瓶颈的地方是什么？
  - 最先出问题的地方肯定是数据库
    - 接下来参考秒杀系统

如果是 IO 密集型的任务，我们可以适当的多分配一点核心线程数，更好的利用 CPU，所以核心线程数可以设置为 8，队列长度还是 100，最大线程池设置为 10。
- 操作系统IO模型
  - 阻塞式IO：当用户进程发起一个IO操作后，内核会去查看数据是否就绪，如果没有就绪，那么该进程会被阻塞，直到数据就绪后才会继续执行。
    - 这种模型的优点是实现简单，缺点是效率低下，因为进程会被阻塞，无法处理其它任务。
  - 非阻塞式IO：当用户进程发起一个IO操作后，内核会立即返回一个错误码，告诉用户进程数据还没有就绪。
    - 用户进程可以不断地轮询内核（发起系统调用），直到数据就绪后再进行读取。这种模型的优点是可以不断地轮询，缺点是效率低下，因为进程需要不断地轮询。
  - 信号驱动IO：当用户进程发起一个IO操作后，会向内核注册一个**信号处理函数**，内核会立即返回一个错误码，告诉用户进程数据还没有就绪。
    - 当内核数据就绪时会发送一个信号给进程，进程便在**信号处理函数**中调用IO读取数据。
    - 这种模型的优点是可以异步地进行IO操作，缺点是需要注册信号处理函数。
  - 异步IO：当用户进程发起一个IO操作后，内核会立即返回，告诉用户进程数据还没有就绪。
    - 内核会为该IO操作注册一个回调函数，当数据就绪后，内核会调用该回调函数进行读取。
    - 内核把整个IO处理完后，才通知进程结果。如果IO操作成功则进程直接获取到数据。
    - 这种模型的优点是可以异步地进行IO操作，缺点是实现复杂。
- IO多路复用（https://zhuanlan.zhihu.com/p/367591714）
  - IO多路复用是一种同步IO模型，实现一个线程可以监视多个文件句柄；
  - 一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；
  - 没有文件句柄就绪时会阻塞应用程序，交出CPU。
  - 在Linux系统下，IO多路复用包括了三种：select、poll、epoll
    - 本质上都是同步IO，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，
    - 而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间
- 线程和进程区别
  - 进程
    - 进程是操作系统中的一个基本概念，是指正在运行的一个程序。
    - 每个进程都有自己的地址空间、数据栈以及其他用于跟踪进程执行的辅助数据。
  - 线程
    - 线程是进程的一部分，是进程中的一个执行单元，是操作系统能够进行运算调度的最小单位。
    - 与进程不同，线程是在同一地址空间中执行的，并共享相同的数据。
    - 线程比进程更轻量级，创建和销毁线程的开销比进程要小。线程之间的切换比进程之间的切换要快得多。
    - 线程之间的通信更容易，但是线程之间的同步需要更加小心。
    - 总之，进程和线程都是操作系统中的基本概念，但是它们之间有很多区别，包括内存使用、资源管理、执行开销、通信等方面。
  - 区别
    - 根本区别：多进程中每个进程有自己的地址空间，线程则共享地址空间；进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位
- 进程调度（CPU调度进程）策略有哪些
  - 单核
    - 先来先服务调度算法（FCFS）：按照进程到达的先后顺序进行调度。
    - 短作业优先调度算法（SJF）：按照进程的执行时间进行调度，执行时间短的进程先执行。
    - 优先级调度算法：按照进程的优先级进行调度，优先级高的进程先执行。
    - 时间片轮转调度算法：按照时间片的大小进行调度，每个进程轮流执行一个时间片。
    - 多级反馈队列调度算法：按照进程的优先级和执行时间进行调度，优先级高的进程和执行时间短的进程先执行。
  - 多核
    - 分类
      - 多物理CPU：通过总线通信，效率比较低
      - 单物理CPU多核：通过L2 cache同学，存储和外设通过总线与CPU通信
    - 调度算法
      - 全局队列调度
        - 操作系统维护一个全局的任务等待队列。
        - 当系统中有一个CPU核心空闲时，操作系统就从全局任务等待队列中选取就绪任务开始在此核心上执行。
        - 这种方法的优点是CPU核心利用率较高。
      - 局部队列调度
        - 操作系统为每个CPU内核维护一个局部的任务等待队列。
        - 当系统中有一个CPU内核空闲时，便从该核心的任务等待队列中选取恰当的任务执行。 
        - 这种方法的优点是任务基本上无需在多个CPU核心间切换，有利于提高CPU核心局部Cache命中率。
      - 目前多数多核CPU操作系统采用的是基于全局队列的任务调度算法。
- 同一台机器，同一个应用程序的线程怎么通信？不同机器之间呢？
  - 线程直接不需要通信（因为内存共享），但要做好同步/互斥，保护共享的全局变量（java的父子线程间可以通过InheritThreadLocal通信）
  - 不同机器间（本质上是进程间通信）
    - 管道(pipe）：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
    - 有名管道 (namedpipe)：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
    - 信号量(semaphore)：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。
      - 它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。
      - 因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
    - 消息队列(messagequeue)：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
    - 信号 (sinal)：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
    - 共享内存(shared memory)：共享内存就是映射一段能被其他进程所访问的内存，
      - 这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。
      - 它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
- 生产者消费者模型
- 内存分配算法
  - 线性分配器（Linear Allocator）：预先创建内存块，然后在内存块上一直分配内存，这些分配出去的内存不用释放，到最后再一次性把内存块回收。
  - 固定大小分配器（Fixed Size Allocator）：将内存块切割成多个固定大小的小块，并将它们链接起来形成一个 freelist；分配的时候从 freelist 取出小块返回；释放的时候将小块重新链接回 freelist。
  - 首次适应算法（First Fit）：从空闲分区链首开始查找，直到找到一个满足其大小要求的空闲分区为止。
  - 循环首次适应算法（Next Fit）：从上次找到的空闲分区的下一个开始查找。
  - 最佳适应算法（Best Fit）：把空闲分区按大小递增的方式形成分区链，找到第一个能满足要求的空闲分区就进行分配。
  - 最坏适应算法（Worst Fit）：把空闲分区按大小递减的方式形成分区链，找到第一个能满足要求的空闲分区就进行分配。
- linux是如何启动的
- 分页和分段的区别
  - 目的
    - 页是信息的物理单位,分页是为了实现非连续分配,以便解决内存碎片问题,或者说分页是由于系统管理的需要.
    - 段是信息的逻辑单位,它含有一组意义相对完整的信息,分段的目的是为了更好地实现共享,满足用户的需要.
      - 比如一个段专门放代码，另一个专门放变量
  - 大小
    - 页的大小固定,由系统确定,将逻辑地址划分为页号和页内地址是由机器硬件实现的.
    - 段的长度却不固定,决定于用户所编写的程序,通常由编译程序在对源程序进行编译时根据信息的性质来划分.
  - 地址空间
    - 分页的作业地址空间是一维的（页号和偏移量）.分段的地址空间是二维的（要多提供一个段号）
- 段页式存储（https://cloud.tencent.com/developer/article/1344772）
  - 分页系统能有效地提高内存的利用率，而分段系统能反映程序的逻辑结构，便于段的共享与保护，将分页与分段两种存储方式结合起来，就形成了段页式存储管理方式。
  - 在段页式存储管理系统中，作业的地址空间首先被分成若干个逻辑分段，每段都有自己的段号，然后再将每段分成若干个大小相等的页。对于主存空间也分成大小相等的页，主存的分配以页为单位。
  - 段页式系统中，作业的地址结构包含三部分的内容：段号  页号  页内位移量
  - 程序员按照分段系统的地址结构将地址分为段号与段内位移量，地址变换机构将段内位移量分解为页号和页内位移量。
  - 为实现段页式存储管理，系统应为每个进程设置一个段表，包括每段的段号，该段的页表始址和页表长度。每个段有自己的页表，记录段中的每一页的页号和存放在主存中的物理块号。
- CPU的缓存一致性协议（MESI）是什么？和Java的volatile关键字的区别和联系
  - 前者保证了多核处理器之间的缓存一致性，但不能解决线程间的可见性和指令重排问题（死锁、数据竞争）
  - 后者刚好是解决这些问题。因此二者的场景不同
- 并发和并行的区别

套接字(socket)
套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。
- 
### 零拷贝
- 应用
  - Java的NIO包中，MappedByteBuffer调用了mmap；transferTo()/transferFrom()底层调用了sendfile()
  - Kafka的消息存储使用的就是Java中的transferTo()/transferFrom()
  - Spark中的shuffle过程的溢写到磁盘，用到了transferTo()
- 零拷贝是指计算机执行IO操作时，CPU不需要将数据从一个存储区域复制到另一个存储区域，从而可以减少上下文切换以及CPU的拷贝时间。它是一种I/O操作优化技术。
- 非零拷贝（从硬盘读出数据，再通过socket发送出去）
  - while((n = read(diskfd, buf, BUF_SIZE)) > 0) {write(sockfd, buf , n);}
    - fd是file descriptor的缩写，即文件描述符
  - IO过程
    - read：把数据从磁盘读取到内核缓冲区（1次），这一步由DMA控制器完成，不需要CPU参与；但需要从用户态切换到内核态（切换1）
      - CPU参与，把数据再拷贝到用户缓冲区（2次），从内核态切换到用户态（切换2），此时read函数返回
    - write：CPU参与，把数据从用户缓冲区写入到socket缓冲区（在内核态，3次），从用户态切换到内核态（切换3）
      - DMA控制器把数据从socket缓冲区，拷贝到网卡设备（4次），上下文切换到用户态（切换4），write返回。
- 零拷贝 
  - 参考：https://zhuanlan.zhihu.com/p/447890038 
  - 目的：减少用户态/内核态的切换次数以及CPU拷贝的次数，不是没有数据拷贝
  - 叫法由来：
  - 方式
    - mmap+write
      - mmap内存映射：虚拟地址和物理地址的映射，可以多个虚拟地址映射到同一个物理地址
      - 用法：把读缓冲区的地址和用户缓冲区的地址进行映射，内核缓冲区和应用缓冲区共享，所以节省了一次CPU拷贝（IO过程中的第2次，因为这俩地址是一个，所以不会发生拷贝）
      - 但是上下文切换过程也是4次
      - 共3次拷贝，2次DMA，1次CPU拷贝；4次上下文切换
    - sendfile
      - 表示在两个文件描述符之间传输数据，它是在操作系统内核中操作的，避免了数据从内核缓冲区和用户缓冲区之间的拷贝操作
      - 过程
        1. sendfile：发起系统调用，从用户态切换到内核态（切换1），由DMA控制器把数据从硬盘中拷贝到内核缓冲区（1次）
        2. CPU将读缓冲区中数据拷贝到socket缓冲区（2次）
        3. DMA控制器，异步把数据从socket缓冲区拷贝到网卡（3次）
        4. 上下文（切换2）从内核态切换回用户态，sendfile调用返回
        - 共3次拷贝，2次DMA，一次CPU拷贝；2次上下文切换
    - 带有DMA收集拷贝功能的sendfile
      - Linux2.4版本以后，sendfile优化升级，引入SG-DMA技术
        - 加入了scatter/gather操作，它可以直接从内核空间缓冲区中将数据读取到网卡
      - 其他与sendfile一样，只是第2步CPU拷贝省去了
        - 改为：CPU把内核缓冲区中的文件描述符信息（包括内核缓冲区的内存地址和偏移量）发送到socket缓冲区
      - 真正的零拷贝，全程都没有通过CPU来搬运数据，所有的数据都是通过DMA来进行传输的
#### DMA控制器（direct memory access）
- 帮忙CPU转发一下IO请求，以及拷贝数据，主要解决解PU观察状态位且按字节发送数据到控制器寄存器 的低效问题（解放CPU）
- CPU将命令写到DMA，之后继续其他工作
- DMA自行操作内存总线，当地址放入总线，完成内存到磁盘的传输（大量数据）

### select poll和epoll的区别
- select和poll差不多，一个是数组（32位1024，64位2048），一个是链表，所以后者没有数量的限制；
- epoll多注册了一个ctrl事件监听。（少数连接的话，epoll性能不一定更高，因为有更多的函数回调）
- 套接字是操作系统在管理，所以硬件的中断反馈给操作系统，进程从操作系统读取套接字的fd，所以有一个内存拷贝的过程，
  - select和poll是轮询每个套接字，每次都要全部拷贝，而epoll是在初始化时拷贝，每次事件触发时直接响应，不需要再复制
#### socket通信简介
- 发送方
  - 发送方向socket的缓冲区发送数据，等待系统从缓冲区把数据取走
  - 通过网卡把数据发出去
- 接收方
  - 接收方的网卡在收到数据之后，会把数据copy到socket的缓冲区
  - 等待应用程序来取
- copy数据的开销
  - 因为涉及到系统调用，整个过程可以发现一份数据需要先从用户态拷贝到内核态的socket
  - 然后又要从内核态的socket拷贝到用户态的进程中去，这就是数据拷贝的开销。
- 数据传输
  - 建立TCP连接
  - 通过四元组唯一定义：ip（client）+ port（client）+ip（server）+port（server）
    - 单机可以有N个ip，因此最大并发为N * 65536
  - 操作系统会为每个socket建立一个fd句柄，
    - 指向我们创建的socket对象，其包含缓冲区、进程的等待队列
  - 对于一个创建socket的进程来说，如果数据没到达，那么他会卡在recv处，
    - 这个进程会挂在socket对象的等待队列中
    - 对cpu来说，这个进程就是阻塞的，它其实不占有cpu，它在等待数据的到来。
  - 当数据到来时，
    - 网卡会告诉cpu，cpu执行中断程序，把网卡的数据copy到对应的socket的缓冲区中
    - 然后唤醒等待队列中的进程，把这个进程重新放回运行队列中
    - 当这个进程被cpu运行的时候，它就可以执行最后的读取操作了


## 真题：有10个消费节点，突然某几个在凌晨宕机了，早上发现有大量消息堆积，如何在不发布代码且不扩容的情况下，快速解决堆积的问题
- 消费线程是否可以配置更大的值
- 摘掉外部流量，全部用来消费消息
- 看消息是否能跳过
  - 如果能，直接跳过，事后回溯（有助于业务快速恢复，如银行业务）
  - 如果不能，分区数多于机器数时，可以加机器；反之加分区数量
- 消息消费的影响因素：吞吐，即并发和单消息处理速度，后者很难改变，只能变前者；加消费线程数


## 设计模式
- 观察者模式中，观察者很多，第一个和最后一个Observer时间间隔很长
  - 耗时在ack上，考虑异步IO

## Netty是干啥的？原理是什么？
- Netty是一个基于NIO的客户端-服务器框架，它提供了易于使用的API，可帮助您快速开发可维护的高性能协议服务器和客户端。
- Netty的优点在于提供了异步的、事件驱动的网络应用程序框架和工具，支持多种协议，如FTP、SMTP、HTTP以及各种二进制和基于文本的传统协议123.

### 线上服务CPU负载高，怎么排查
- top找到占用CPU最高的线程
- jstack查看线程堆栈，找到对应的线程信息
- 定位到线程池，分析代码
- 注意1：jstack可能会把线上打挂，因此业务量不大或测试环境复现时分析
- 注意2：jstack用的是十六进制，top是十进制，因此需要转换
- 实际：查两次代码diff或重启就能解决大部分问题

### 查询接口调优，不能用缓存，要求实时性，怎么办？
- 优化查询语句和数据库的配置，以提高查询效率
- 考虑使用异步处理来优化耗时操作
- 如果需要跨库查询多个服务，可以考虑使用分布式事务来保证数据的一致性[https://blog.csdn.net/YYQ_QYY/article/details/105996347]

### 线程池核心线程数20，最大600，阻塞队列200，当qps为200时，请求（调用第三方，一个长时间的任务）阻塞超时，请问如何提高吞吐量
- 使用更高效的线程池实现，如ForkJoinPool
- 将长时间任务拆分为多个小任务，并行执行
- 使用异步非阻塞的方式处理第三方调用，避免阻塞线程池

### 滑动窗口限流怎么做？
- 可以采用一个固定大小的时间窗口统计请求的数量
- 如果请求超过了设定的阈值，则进行限流处理
- 实现：采用双端队列实现，每次新的请求来时，过期的请求移除，并判断当前队列中的请求是否超过阈值

#### 桥能承重600kg，现在有700kg的牛，怎么过河（系统承载600qps，700qps怎么办）
- 能不能把700qps打平，分次过（牛宰了分次过）
- 只服务其中的600qps，其他的拒绝（牛饿瘦了过）
- 用别的服务顶一下（临时找船过）
- 加机器解决（加固桥，能承重更多）
- 重构优化项目（重新造一个新桥）

~~#### Bloom Filter原理~~

### 10亿个key中如何判断某个key是否存在？
要求：内存空间不能太大；500w查询流量qps
- redis的bitmap实现，通过key hash下标位置
  - 不能解决hash冲突的问题
- hash 后布隆过滤器能判断一定不存在，但无法判断是否存在
- ART前缀树？？？

### 真题：限流，1分钟处理1000个请求
- 单线程
- 多线程
- 参考：分布式限流器怎么实现

#### 如何实现session共享存储？
- https://blog.csdn.net/siyuanwai/article/details/119115945
- 粘性session 
  - 粘性session 是指Ngnix 每次都将同一用户的所有请求转发至同一台服务器上，即将用户与服务器绑定。 
- 服务器session 复制 
  - 即每次session 发生变化时，创建或者修改，就广播给所有集群中的服务器，使所有的服务器上的session 相同。 
- session 共享
  - 缓存session，使用redis， memcached。
- session 持久化
  - 将session 存储至数据库中，像操作数据一样才做session。
  

### 场景题：数据量很大的情况下，需要先从db获取用户基础信息，然后根据用户基本信息查询redis中关联的信息，如何提高性能？（忽略OOM）

### 场景题：Mysql的InnoDb和MyISAM引擎，使用自增主键，突然断电后重启，自增主键会连续吗？为什么

### 场景题：并发场景下，QPS突然激增，reids只能吸引自增ID，结果master宕机了，比如id迅速从0增加到几万，来不及同步，可以保持一致性吗？怎么解决？

### 10g数据，2g内存，如何去重？
- 参考：海量数据面试题

### 几十万QPS的全局唯一分号器
- 雪花算法（核心是提前生成好一批存起来，用的时候直接取）
  - 第一位为什么不用：符号位，用的都是正数，所以第一位用不上
- 构成
  - 1位不用
  - 41bit的时间戳（毫秒），可以用69年（项目开始时间往后）
  - 10bit：工作机器ID或机房ID + 机器ID
  - 12bit 序列号，共4096个
- 回拨时间，会导致id重复的问题
  - 回拨时间小的时候，不生成 ID，循环等待到时间点到达。
  - 要么超过一定大小的回拨直接报错，拒绝服务，
    - 或者利用拓展位，回拨之后在拓展位上加1就可以了，这样ID依然可以保持唯一
    - 要么从机器id中，要么从序列号中，腾出一定的位，回拨时该位+1

### 大文件，求出其出现频率TOPK的词
- 分治思想，先把大文件分到5000（比如）个小文件里（比如hash）
- 对每个小文件求出TOPK词频
- 再归并排序


## 算法题
- 加油站
- k个一组翻转单链表
- 二叉树第k层偶数和
- 判断一个数组数据是否是二叉搜索树的后续遍历
- 单例模式，
- 两个list的区间交集
- 二叉树锯齿形层次遍历
- 字典序的第k小数字
- 二叉树以中序遍历方式转换成双向链表，空间O(1)
- 给定一个n*m的数组，每个位置一个分数，求左上到右下的最大分数
- 将一个无序数组插入1g个元素的有序数组中
- 对一个100g的文件去重
- 可怜的小猪
- 盛最多水的容器
- 174地下城游戏
- 二叉树中序遍历
- 中文字符转化为数字（五百三十万六千零三 -> 5306003），输入在一亿之内
- 二维数组，行递增，列也递增，能否找到某个数
- 最长回文子串
- 快排的基本思想，时间和空间复杂度？
- 归并排序的应用场景，时间和空间复杂度？
- 编辑距离
- 字符串a和b相减的结果
- 最小覆盖子串 76
- 删除排序链表中的重复元素II 82
- 返回第N行的格雷码
- 300 最长递增子序列
- 674 最长连续递增子序列
- 最长递减子序列 & 最长连续递减子序列
-
### 实现lru（参考: _146LRUCache）
一个map（键为元素的值，值为node本身），内部放node，实现O(1)时间内判断是否在集合中；节点采用双端队列，方便删除、新增节点；
1. get：首先判断map中是否存在元素，不存在返回-1；存在则从map中get节点，把节点move2Head，返回节点的值即可
2. put：首先判断map中是否存在，不存在则新建节点并添加链表的头，并将其添加到map；存在则更新map中的值，并把节点move2Head
- 注意当判定size >= capacity时，要找到tail的前置节点curNode，remove map中的节点，并删除curNode
3. 私有方法
- deleteNode：找到pre和next节点，相互连接，把curNode的pre和next置为null，size--
- addHeadNode：处理前置哨兵head，让head和curNode相连，原先的head.next连接到curNode的后面
- move2Head：先deleteNode，再add2Head




## 计算机网络

- https的原理？对称加密和非对称加密（RSA、AES和证书的原理）
- http和https区别
  - http：无状态、无链接（通过 cookie 和 session 来记录 http 状态）
  - HTTPS 是支持 TLS 加密的 HTTP。HTTPS 使用 TLS (SSL) 来加密普通的 HTTP 请求和响应，使它变得更加安全
- http状态码，2xx和3xx分别是什么状态
  - 1XX：消息状态码。
    - 100：Continue 继续。服务器已经接收到请求头，并且客户端应继续发送请求主体
  - 2XX：成功状态码。
    - 200：OK 请求成功。一般用于 GET 与 POST 请求。
  - 3XX：重定向状态码。
    - 301：Moved Permanently 永久移动。请求的资源已被永久的移动到新 URI，
      - 返回信息会包括新的 URI，浏览器会自动定向到新 URI。今后任何新的请求都应使用新的 URI 代替。
    - 302：Found 临时移动，与 301 类似。但资源只是临时被移动。客户端应继续使用原有URI。
    - 304：Not Modified  未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。节省带宽和开销
  - 4XX：客户端错误状态码。
    - 403：Forbidden    服务器理解请求客户端的请求，但是拒绝执行此请求。
    - 404：Not Found 服务器无法根据客户端的请求找到资源（网页）。
      - 通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面。
    - 405：Method Not Allowed 客户端请求中的方法被禁止。
  - 5XX：服务端错误状态码。
    - 500：Internal Server Error 服务器内部错误，无法完成请求。
    - 502：Bad Gateway 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应。
      - 上游服务器和网关/代理使用不一致的协议交换数据（一般是开代理了）
    - 503（服务不可用）： 服务器目前无法使用（由于超载或停机维护）
    - 504：Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求。
- 线上500如何排查
  - 看日志、看配置、看代码
  - 看依赖项、看数据库连接、看网络连接
- 三次握手，四次挥手
  - 三次握手
    - 客户端向服务器发送一个SYN报文，请求建立连接。该报文包含一个随机生成的序列号。
    - 服务器收到SYN报文后，回复一个SYN+ACK报文，表示确认客户端的请求，并告诉客户端自己的序列号。同时，服务器也会生成一个随机的序列号。
    - 客户端收到SYN+ACK报文后，回复一个ACK报文，表示确认服务器的请求，并告诉服务器自己的序列号。此时，连接已经建立完成。
  - 四次挥手
    - 客户端向服务器发送一个FIN报文，请求关闭连接
      - 此时Client端进入FIN_WAIT_1状态，表示Client端没有数据要发送给Server端了。
    - 服务器收到FIN报文后，回复一个ACK报文，表示确认客户端的请求。
      - Client端进入FIN_WAIT_2状态，Server端告诉Client端，我确认并同意你的关闭请求
    - 服务器向客户端发送一个FIN报文，请求关闭连接。
      - 同时Client端进入LAST_ACK状态。
    - 客户端收到FIN报文后，回复一个ACK报文，表示确认服务器的请求。
      - Client端进入TIME_WAIT状态。Server端收到Client端的ACK报文段以后，就关闭连接
      - Client端等待2MSL（2倍报文段的最大生存时间）的时间后依然没有收到回复，则证明Server端已正常关闭，那好，Client端也可以关闭连接了
  - 为什么需要三次握手
    - 场景
      - 考虑client的链接请求滞留的情况，到达服务端时已经失效很久了
      - 此时server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求，
      - 于是就向client发出确认报文段，同意建立连接。
      - 由于client并没有发出建立连接的请求，因此不会理睬server的确认
    - 问题
      - 如果没有3次握手，这种情况下Server认为连接已经建立了，但客户端并不认为有链接；server在傻等，很多资源就白白浪费掉
      - 如果有，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。
  - 为什么会有close-wait
    - 第一点：保证TCP协议的全双工连接能够可靠关闭：
      - 如果Server端没有收到Client端的ACK报文，Server端就会在超时之后重新发送FIN
    - 第二点：保证这次连接的重复数据段从网络中消失
      - 避免下次链接时，上次链接发送的所有报文段都已经从网络上消失了
- 从输入url到页面加载完毕过程，DNS寻址
- tcp如何实现拥塞控制
  - 慢开始算法：通过拥塞窗口实现，
- TCP的粘包和丢包？具体是怎么实现的
  - Socket编程：客户端端口+服务端端口+客户端IP+服务端IP+传输协议组成的五元组可以明确的标识一条连接
  - 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。 
  - 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。
  - 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。
  - 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。
  - 解决办法
    - 发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。
    - 发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
    - 可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。
- http post的两次发送


## Zookeeper
- 发布订阅功能是什么？一般用做什么场景？是怎么实现的？
  - 对节点监听，节点的数据发生变化，客户端会收到通知（可以多个订阅者订阅一个主题），但不适合大规模的消息
- 一般用zk干啥
  - 分布式锁、命名服务（存储分布式服务的配置信息、元数据等）、配置管理（变更时通知系统）、分布式队列、分布式协调（选主、成员管理等）、高可用性（节点故障时自动选主）
- zk属于AP、CP还是CA？
  - CP，是如何保证的？
- Raft算法的领导选举过程？工作原理是啥？
- zk的watch机制？是怎么实现的？
- 命令、配置和管理是如何实现的

## Kafka
- 简述kafka的架构设计
  - producer：消息生产者，自己决定向哪个partaion发送数据，hash或轮询
  - Cluster（broker）
    - 【物理】Controller：broker的领导者，主写主读，它负责管理整个集群中所有分区和副本的状态（选举产生）
    - 【逻辑】分为多个Topic（一个队列），每个topic有多个partition
      - 每个partition有多个副本（分布在多个broker上），一个Leader和多个Follower
      - 生产者发送数据和消费者消费数据，都是和Leader交互
      - Follower实时从Leader中同步数据，保持数据同步
      - 故障发生时，某个Follower会成为新的Leader
  - Consumer Group：
    - 消费者组，消费者组内每个消费者负责消费不同分区的数据，提高消费能力。逻辑上的一个订阅者。
  - Zookeeper（kRaft，2.8版本开始，3.0基本完成）
    - 存储和管理集群信息。
    - Broker和Topic 注册到 Zookeeper，生成 Znode 的临时节点。
    - Broker 、Topic、Offset 和Partition的关系，包括 Consumer 的关联关系，都是存储到 zk 的。
    - Leader 节点的选举模式也是使用Zookeeper的选举机制。
- 简述下工作机制
  - Kafka的基本结构由broker、topic和partition组成。
  - 一个broker是一个Kafka实例，每个topic包含一组相关的消息，而partition是消息的物理存储单位。
    - 多个broker组成集群，某个Broker会成为集群控制器（Cluster Controller），负责管理集群
    - 包括分配分区到 Broker、监控 Broker 故障等
  - Kafka使用推拉模型将生产者和消费者分离，为消息传递系统中的消息数据提供持久性，以允许多个消费者。
  - Kafka的消费者主动地去Kafka集群拉取消息时，也是从Leader分区去拉取数据。
  - Kafka使用Epoch number来处理脑裂问题，同时也可以使用Quorum来防止脑裂。
- 设计目标
  - 以时间复杂度为 O(1) 的方式提供消息持久化能力，即使对 TB 级以上数据也能保证常数时间复杂度的访问性能。
  - 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输。
  - 支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。
  - 同时支持离线数据处理和实时数据处理。
  - Scale out：支持在线水平扩展。
- Kafka的存储
  - Kafka 的消息是存在于文件系统之上的，高度依赖文件系统来存储和缓存消息
  - 任何发布到 Partition 的消息都会被追加到 Partition 数据文件的尾部，这样的顺序写磁盘操作让 Kafka 的效率非常高
    - Kafka 高吞吐率的一个很重要的保证
    - 消费后文件不会删除，删除策略是针对过期的 Segment 文件
  - 同一个 Topic下有多个不同的 Partition，每个 Partition 都为一个目录，而每一个目录又被平均分配成多个大小相等的 Segment File（文件存储的最小单位） 
    - 由 index file 和 data file 组成，他们总是成对出现
- 消费者
  - 如果应用需要读取全量消息，那么请为该应用设置一个消费组；
    - Kafka一个很重要的特性就是，只需写入一次消息，可以支持任意多的应用读取这个消息
  - 如果该应用消费能力不足，那么可以考虑在这个消费组里增加消费者。
    - 不能多于分区数，一个分区只能被一个消费者消费
- 消费组与分区重平衡（保证了高可用和水平扩展）
  - 新增消费者（或离开）时，存在需要消费分区（或释放之前消费的分区问题），叫重平衡
    - 在重平衡期间，所有消费者都不能消费消息，因此会造成整个消费组短暂的不可用
  - 消费者探活
    - 消费者通过定期发送心跳（hearbeat）到一个作为组协调者（group coordinator）的 broker 来保持在消费组内存活。
    - 这个 broker 不是固定的，每个消费组都可能不同。
    - 当消费者拉取消息或者提交时，便会发送心跳。
  - 如果消费者超过一定时间没有发送心跳，那么它的会话（session）就会过期，组协调者会认为该消费者已经宕机，然后触发重平衡
    - 通常可以优雅关闭，这样消费者会发送离开的消息到组协调者，这样组协调者可以立即进行重平衡而不需要等待会话过期。
  - 触发balance的时机
    - 消费组成员发生了变更，比如有新的消费者加入了消费组组或者有消费者宕机
    - 消费者无法在指定的时间之内完成消息的消费
    - 消费组订阅的Topic发生了变化
    - 订阅的Topic的partition发生了变化
- 如何保证全局顺序？
  - 没有办法。Kafka 只会保证在 Partition 内消息是有序的，而不管全局的情况。
- Partition中被消费的消息是何时删除的
  - 无论消息是否被消费，除非消息到期 Partition 从不删除消息。
  - 例如设置保留时间为 2 天，则消息发布 2 天内任何 Group 都可以消费，2 天后，消息自动被删除。
  - Partition 会为每个 Consumer Group 保存一个偏移量，记录 Group 消费到的位置
- 为什么消费消息是pull模式？
  - push 模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。
  -  pull 模式则可以根据 Consumer 的消费能力以适当的速率消费消息。
- 如何防止脑裂
  - 副本机制
    - 每个分区多副本，一个副本被选为主（处理读写请求），出故障时选举新的主
  - 心跳机制
    - 通过心跳检测副本的存在，否则标记为离线，以及时发现和处理故障副本
  - zk的协调（新版本用了kRaft）
    - 通过zk选举控制器的领导者
- 如何保证可靠性
  - 对于一个分区来说，它的消息是有序的。如果一个生产者向一个分区先写入消息A，然后写入消息B，那么消费者会先读取消息A再读取消息B。
  - 当消息写入所有in-sync状态的副本后，消息才会认为已提交（committed）。
    - 这里的写入有可能只是写入到文件系统的缓存，不一定刷新到磁盘。
    - 生产者可以等待不同时机的确认，比如等待分区主副本写入即返回，后者等待所有in-sync状态副本写入才返回。
  - 一旦消息已提交，那么只要有一个副本存活，数据不会丢失。
  - 消费者只能读取到已提交的消息。
- kafka的副本怎么管理的
  - 在producer写入数据时会通过副本机制对当前数据进行复制备份，其他分区副本通过拉取的方式进行数据同步，依赖多副本机制进行故障转移。
  - HW: 高水位，标识consumer可见的offset，取所有ISR中最小的那个，只有所有的副本都同步完成HW才会增加，消费者只能消费到HW之后的数据 
  - LEO: 每个partation的log最后一条message位置
  - AR: 所有的分区副本集合
  - ISR: 同步的分区集合队列（In-Sync Replicas，和主一致的，包括leader），属于AR的一个子集，ISR中如果同步慢了或挂起会被t出ISR队列。
    - 只要保证 ISR 中的 Replica 数量大于 2(ISR 包括 Leader)，即便出现 Leader 突然故障下线的情况，也能保证消息不丢失
  - OSR：从同步队列中被提出的分区集合（和主不一致的Replica）
  - 当partation leader挂掉后由Controller在ISR集合中顺序查找出第一个选举新leader
- kafka如何解决消息丢失？有哪些情况？分别怎么处理？
  - 生产者向leader发数据时通过request.required.acks参数设置数据可靠性的级别。
    - 1（默认）： producer在ISR中的leader已成功收到的数据并得到确认后发送下一条message。如果leader宕机了，则会丢失数据。
    - 0：producer无需等待来自broker的确认而继续发送下一批消息。这种情况下数据传输效率最高，但是数据可靠性确是最低的。
    - -1或者all：producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高。
      - 通过设置ack=1，broker内部做副本同步保证broker内部数据不丢失。
  - Consumer保证消费数据不丢失，默认情况下，当消费者消费到消息后，会自动提交offse。
    - 但是如果消费者消费出错，没有进入真正的业务处理，那么就可能会导致这条消息消费失败，从而丢失。
    - 可以通过开启手动提交位移，等待业务正常处理完成后，再提交offset。
- 消息被顺序生产，顺序消费，但不同进程的消费速度不一致，如何保证顺序？
  - 将所有消息发送到同一个分区
    - 在发消息的时候指定Partition Key，Kafka对其进行Hash计算，根据计算结果决定放入哪个Partition。
    - 这样Partition Key相同的消息会放在同一个Partition。
    - 此时，Partition的数量仍然可以设置多个，提升Topic的整体吞吐量。
  - 使用单个消费者
  - 如果消费者采用多线程消费一个partition怎么办？
    - 写N个queue，将具有相同key的数据都存储在同一个queue，然后对于N个线程，每个线程分别消费一个queue即可。
- 持久化内存满了怎么办？只能迁移吗？
  - 删除旧数据（手动）
  - 扩容硬盘空间（云上自动扩容）
  - 压缩数据，当消息被生产者发送到Kafka时，可以使用制定的压缩算法对消息进行压缩。而在消费者端，Kafka会自动解压消息
- kafka的一致性算法
  - 选举一个主，再由主来读写
- 分区数越多越好吗
  - 在一定条件下，分区数的数量是和吞吐量成正比的，分区数和性能也是成正比。
  - 超过了一定限度，**客户端和服务端**需要使用的内存会激增 
    - 服务端在很多组件中都维护了分区级别的缓存，分区数越大，缓存成本也就越大。
    - 消费端的消费线程数是和分区数挂钩的，分区数越大消费线程数也就越多，线程的开销成本也就越大
    - 生产者发送消息有缓存的概念，会为每个分区缓存消息，当积累到一定程度或者时间时会将消息发送到分区，分区越多，这部分的缓存也就越大
  - 文件句柄的开销，partation底层存储对应一个log文件，文件句柄数量增加 
  - 增加数据同步负担，降低高可用
- kafka为什么那么快，吞吐量高
  - kafka生产消息时通过异步发送机制，首先通过main线程将数据缓存起来，sender线程批量搬运数据，broker定时去pull数据。
  - 数据批量读写、批量压缩，消息发送到broker之前会压缩消息，达到一定数据量压缩一次性发送。 
  - 顺序写磁盘：新的消息顺序添加到日志文件末尾，而且磁盘上的 数据不会一直存着，后台会维护一个线程 来定期检测是否有数据该删除。
  - PageCache页缓存：充分利用Linux操作系统对磁盘的访问优化，Cache层在内存种缓存了磁盘上的部分数据。
    - Broker收到数据后先将生产者的数据写入page cache，再定期刷到磁盘中 
  - 零拷贝技术：通过 NIO 的 transferTo/transferFrom 调用操作系统的 sendfile 实现零拷贝(高频考点)。
  - 数据分区分段 + 稀疏索引：Kafka 的 message 消息实际上是分布式存储在一个一个小的segment中的，
    - 每次文件操作也是直接操作的 segment。为了进一步的查询优化，Kafka 又默认为分段后的数据文件建立了索引文件，就是文件系统上的 .index文件。
    - 这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度。

## ES
- 数百T的数据放在ES中，涉及聚合操作，怎么实时显示？
  - 区分出冷热数据，看热数据是否能做到实时显示
  - 相对固化的需求做预聚合（如flink），再做最终聚合
  - 相对灵活的需求，可以采用OLAP引擎来做
    - 低qps，高延迟的场景：presto/imapla，hive/spark都可
    - QPS高，时延低：flink预计算后，存入HBase，查询时对最终结果进行逻辑聚合处理
      - 缺点是链路比较长

## Doris
- 架构
  - FE：Doris的管理节点，主要负责用户请求的接入、查询计划的解析、元数据的存储和集群管理相关工作
    - Leader、Follower和Observer三种角色。
    - 默认一个集群只能有一个Leader，可以有多个Follower和Observer。
    - 其中，Leader和Follower组成一个Paxos选择组，如果Leader宕机，剩下的Follower会自动选出新的Leader，保证写入高可用。
    - Observer同步Leader的数据，但是不参加选举。如果只部署一个FE，FE默认就是Leader。
    - 主要包含存储管理模块、状态管理模块、协调模块、元数据模块和元数据缓存模块。
      - 存储管理模块负责管理所有的元数据信息，包括表信息、Tablet信息、Tablet的副本信息等，还负责管理用户的权限信息（即用户的认证信息和授权信息）和数据的导入任务等。
      - 状态管理模块负责管理所有BE进程的存活状态、查询负载等非持久化信息，并提供发布订阅接口。
      - 协调模块负责接收用户发来的请求，然后进行语句解析、生成执行规划，根据当前集群的状态，对执行规划进行调度。
      - 元数据模块负责对元数据的读写，只有Leader角色拥有此权限。
      - 元数据缓存模块负责同步元数据，以供语句解析、生成执行规划，主要是Follower和Observer角色拥有此权限。
  - BE：主要负责数据存储、查询计划执行。
    - 可以无限扩展，并且所有BE节点的角色都是对等的。在集群足够大的情况下，部分BE节点下线不影响集群提供服务
    - 部分BE节点下线不影响集群提供服务。
    - BE节点主要由存储引擎和查询执行器组成。
      - 存储引擎负责管理节点本地的Tablet数据，发送或者接收数据并保存副本，定期合并、更新多个版本的数据，以减少存储占用。
      - 存储引擎还负责接收来自查询执行器的数据读取请求和批量数据导入请求。
      - 在MPP（Massively Parallel Processing）集群中执行查询时，会分解为一个树状的执行树，由Coordinator来协调执行，
        - 树的叶子节点也叫计划片断(PlanFragment)，每个PlanFragment分配一个BE节点的查询执行器。
- Doris支持Aggregate、Unique和Duplicate三种模型 

### 对比常见的olap引擎（从架构层面）
- Hive：基于Hadoop的数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的SQL查询功能。学习成本低，适合数据仓库的统计分析.
- Spark SQL：将SQL查询与Spark程序无缝集成，可以将结构化数据作为Spark的RDD进行查询。支持访问hive、json、parquet等文件的数据.
- Presto：支持标准的ANSI SQL，包括复杂查询、聚合、连接和窗口函数。支持跨数据源的级联查询，所有的查询处理是在内存中，性能很高.
- Kylin：支持超大规模数据的交互式分析，采用了一种叫做“Cube”的技术，可以将海量数据压缩到一个或多个Cube中，提供快速的查询.
- Impala：基于内存的分布式SQL查询引擎，支持Hadoop的HDFS和HBase存储系统，可以快速查询PB级别的数据.
- Druid：支持实时数据摄取和查询，可以快速查询PB级别的数据，支持多维度的聚合查询3.
- Clickhouse：支持实时数据摄取和查询，可以快速查询PB级别的数据，支持多维度的聚合查询，性能很高.
- Doris：支持实时数据摄取和查询，采用分布式列式存储和分析系统，支持多维度的聚合查询，支持SQL语言.
- ES：一种基于Lucene的分布式搜索和分析引擎，可以用于实时数据摄取和查询，支持多维度的聚合查询，支持SQL语言
