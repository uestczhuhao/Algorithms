## 美团
### 治理分析项目
- Mysql
  - 提前聚合已知维度，可扩展性不高
    - 租户（100个）-治理项（15个）- 时间（365天）
    - 用户（1.6w）- 治理项（15个）- 时间（365天）
- ES
  - 增加组织架构维度（4000），不能提前聚合
  - 存放明细数据（600w + 每天5w增量），取治理状态为缓慢变化维，以开始-结束时间为拉链，做拉链表
    - 事后证明除了缓慢变化维，其余字段也会发生变化，如待治理量，业务归属等
- Doris（向量化计算）
  - 存放所有明细数据，所有维度现场聚合计算（需要秒级内返回）

- 组织架构展示
  - 无限级N叉树结构
  - 拓补排序（BFS）

### 智能治理规则
- easy-rules引擎
  - Rule、Condition、Action、Facts
  - RulesEngine.fire(rules, facts)，定义规则类，创建事实对象，执行规则引擎，根据规则的条件判断执行相应的动作
- 用于资产分配、拉群等功能
  - isNeedAssign条件满足，则分配
  - groupStrategy条件满足，则拉群（每次/首次 执行）

### 资产管理平台
- SpiffWorkflow框架
- Celery框架
  - 采用带哨兵模式的主从模式的Redis充当Celery的Broker角色
- 降幅本需求中，采用redis充当fd的分布式锁以控制并发
- 工作流是一个SpiffWorkflow工作流，每一个task即是spiff的task（可以构成上下游依赖关系），又是一个Celery task（可以分布式执行）
  - 通过让Celery task继承spiff的task来实现
- 需要跨天的工作流（自定义回收站机制），注册一个trigger，然后用BlockingScheduler在内存中调起执行（间隔一分钟）
- 状态流转
  - 前提
    - 所有的节点都继承TaskSpec，运行时都是一个task（spiffworkflow框架下的task）
    - CeleryAction继承Celery，同时集成TaskSpec
    - 业务中按需继承CeleryAction，如果需要异步执行，则继承之
  1. 根据spiffworkflow的规范，每个节点都是一个task，通过connect完成上下游链接 
  2. 每次执行时，先生成工作流实体workflow（基于元数据workflowSpec，其中包含TaskSpecs以及上下游依赖关系） 
  3. workflow由多个task组成，每个task是其TaskSpec的一个实例
     1. 其中某些task继承了CeleryAction，在其运行（_start方法）时，会调用apply_async方法异步执行，然后把任务状态置为WAITING，然后返回
        1. 这一步可能是多个celery task，各自执行，按组拿结果，如删分区的fin_delete、降副本任务
     2. 执行完成之后，调用callback，此时调用try_complete（内部是complete_all方法），此时找到WAITING状态的（celeryAction）任务，调用celery的AsyncResult获取其状态（在redis上维护）
        1. 如果已经结束，则调用_update_hook，则把当前任务置为ready，并标记last_task，complete_next返回false，跳到步骤4
        2. 如果还未结束，直接返回（当前task还是WAITING状态，等待下一轮执行），complete_next返回false，complete_all循环退出，跳到步骤2，等待其他的任务执行完成
     3. 从标记的last_task开始，把它们置为completed，并在后置函数_on_complete_hook中触发child的task执行 ，直到每一个task都执行完（complete_all执行完成并写库，complete_next返回false，循环退出）

- 中间表、测试表等，注册规则（自定义规则引擎）
  - 主要是filter（and/or）和action，在创建时指定

### 数据同步平台
- lambda 架构实现元数据同步
- databus+Kafka+实时同步服务


### 一些辅助信息
#### 治理诉求（分角色）
- 角色：业务负责人
- 核心诉求： 
  - 成本流向，钱（成本）花在哪（哪个项目or哪个业务目标），花的值不值 
  - 治理目标怎么定，投多少人能拿多少收益

- 角色：管治接口人
- 核心诉求： 
  - 预算填报高效且合理，资源分配、使用高效且便捷 
  - BG/核算单元粒度的预算->使用->成本的一站式分析诉求 
  - 成本发生前的成本管治以及成本发生后的评估->问题分配->治理跟进->效果分析的一站式治理诉求 
  - 除成本外，对于规范、质量、安全等也有管治诉求

- 角色：预算review专家组
- 核心诉求： 
  - 核算单元、租户、资源等维度的预算、交付、使用等分析以及洞察能力 
  - 清晰的预算展示形式以及review评价能力、review后的建议执行跟进

- 角色：数据RD
- 核心诉求： 
  - 分配的治理问题归属正确、判定正确，有行之有效且高效的治理措施，治理后能立即给出反馈（治理成功or失败）


#### 治理项：
1. 存储 
- 无效存储指标：90天前创建，且最近90天内无应用层访问热度的表（包含该表及下游表） 
- 生命周期配置不合理指标：生产表中未配置生命周期的分区表 
- 存储选型不合理指标：未采用合理的存储格式（ORC）；比如采用text格式进行存储 
- 冷数据：对于有长时间保存需求的重要数据，且使用频次极低（小于2次/年） 
- 表冗余：生产全量表的同时，使用同样的参数生产了快照

2. 计算（spark参数调整）
- 无效任务：生产出的表超过90天，且最近90天内无应用层访问热度的表 
- 低内存利用率：近30天spark作业内存利用率平均值低于60% 
- 高失败率任务：数仓生产任务中，最近30次调度内，每7个调度内至少有一次调度失败 
- 暴力扫描：扫描分区大于90天，二级以上分区汇总到一级天分区；扫描平均每分区大小大于500M或者总分区大小大于100G 
- 产出持续一致任务：最近15天任务产出数据相同
- 无效dashboard：最后访问日期在180天前，且注册了调度的魔数dashboard

3. 实时Flink任务
- 无效Flink任务：任务和递归下游任务未写入Tair且关联Topic无下游消费
- 无输入flink任务：Flink任务中所有算子的输入数据量持续30天为空的任务
- 低资源利用率flink任务：任务的近30天CPU利用率峰值或内存利用率峰值低于65%
- 并发配置不合理：max(source/sink)的并发 > RT页面配置的并发
- 无状态任务：flink任务的checkpoint 状态大小 < 1M
- checkpoint耗时短延任务：一周内CheckPoint最大耗时<10s


4. Kafka Topic：
- 无效Kafka topic：近30天内，topic输出流量为0
- 低输出Kafka topic：近30天内，topic输出流量/输入流量<0.01

#### 元数据需求
- 表：热度，血缘，基础（生命周期，存储格式）
- 任务：内存使用，失败率
- flink作业：内存利用
- kafka topic：输出的信息的topic信息

#### 治理相关
- 治理手段：删表、删分区、配置生命周期、转orc压缩，转冷存、改任务配置参数（如spark任务）

- 链路：资产分析（发现问题，制定目标） -> 资产评估（筛选问题资产，分配治理任务） -> 治理动作（自动规则，运动式治理） -> 治理收益

- 事前：基于检查项阻断上线/资源参数推荐    事中： 业务参数进行调优（基于历史，HBO比较通用）     事后：通用治理项以及业务自定义治理项

## 小米
### 调度器
#### 高可用
- master
  - 多master，无中心结构，把任务拆分成多个流程，每个流程一个分布式锁，多机抢锁处理相应的流程
  - 配合机器宕机检查报警机制
- worker
  - 每个机器上运行一部分任务，配合机器宕机检查报警机制

#### 容错
- 任务放置在redis上
  - key为当前worker的id，value存放task的基本信息，包含id、任务名、状态等
  - 不进行水平漂移
    - 原因是部署服务的频率远大于机器不可用的频率，所以设计成机器重启时，自动从redis上获取自身的task的方式
- 流程上是幂等的
  - 利用消息队列的ack机制
    - master作为生产者往kafka中放消息时，接收到ack，才把任务从READY置为DISPATCHED；若为error，则重新置为CREATED，等待下一次轮询
    - worker作为消费者，在把任务submit到agent时，才会通知消息队列，后者才会把偏移量往前移，防止遗漏task信息
  - 无锁编程配合兜底接口，保证最终一致性
    - worker submit task时，需要询问master是否可以提交，master接收到后，查看task状态，如果是DISPATCHED，则返回true（同时把task置为PREPARING），worker再提交
    - agent执行时，询问master是否可以运行，master接收到后，查看task状态，如果是PREPARING，则返回true（同时把task置为RUNNING）
    - agent提交spark作业后，子进程在拿到appId后，记录下来并退出；
      - cloud运行完后会回调agent；
      - 后续每5分钟调用接口查询作业运行情况（兜底查询，防止回调丢失）
  - 例行查询卡在某状态时间过长的task
    - 如认为READY状态超过10min即为异常，因为往Kafka中放任务一般是毫秒级，不会超过10min

#### 原有调度器问题
1. 基于Akka Actor模型，海外与国内网络不通畅时，国外的actor容易形成单独的集群
2. 全局DAG，内存和构建时间上有瓶颈
3. 采用手动输入上游任务id的交互方式上，使用成本较高

### 未做的部分
1. 系统监控&运维能力
2. 按优先级调度
   1. 工作流级别的优先级 & 任务级别的优先级
   2. 根据队列的不同，先消费高优先级的任务（参考Celery）
3. 自动监控master & worker的宕机和故障转移
   1. master：由于是多主，每台主地位相同，因此未做额外的故障转移
   2. worker：考虑到机器宕机且不可用的概率（万分之几）较小，设计为手动拉起的形式，应该考虑自动化

#### 主要概念
- https://www.processon.com/diagraming/5ef176307d9c0844202ef658
- 每次调度的最小执行单位，是一个dag，还是一个task
