## Redis
- redis单线程消费，怎么将结果原路返回？（套接字事件与redis的处理器相关联，哪个套接字发出的命令，命令回复处理器就返回给哪个套接字）
- Redis的性能瓶颈（机器内存和网络带宽，执行命令分 发送 排队 执行 返回  四个阶段，后者可以用打包多次命令，一次发送方法部分解决）
- Redis有哪些数据结构（sds，压缩表ziplist，链表linkedlist，字典hashtable，整数集合intset，跳表skiplist）
- 布隆过滤器怎么实现（bitmaps和Redisson）
  - bitmaps（gitbit key offset； setbit key offset value）
    1. 创建向量位图，并设置其值为0 
    2. 准备hash函数数组 
    3. 准备已有元素集合 构建阶段 
    4. 每个元素循环执行hash函数,并且把结果写入向量位图上
    5. 接收判断元素循环执行hash函数，获得对应值
    6. 判断接收元素所算出的结果，
       - 如果对应位图全为1，那么这个元素有可能存在于集合中
       - 如果结果存在1个或以上为0，那么这个元素比不存在于数组中
  - Redisson是一个框架，实现了布隆过滤器的API，底层就是理由Bitmap实现的
- redis从库查询过期键（不会主动删除，等主库的del命令，会一段时间那还能访问，但3.2以上版本会先判断是否过期，过期返回null）
- Redis的lua脚本为何是原子的（redis会为lua脚本执行创建伪客户端模拟客户端调用redis执行命令，伪客户端执行lua脚本是排他的）


### Redis的单线程问题（高性能问题）
#### Redis 只有单线程吗？
- Redis 是单线程的，主要是指 Redis 的网络 I/O 线程，以及键值的 SET 和 GET 等读写操作都是由一个线程来完成的。
- 但 Redis 的持久化、集群同步等操作，则是由另外的线程来执行的。
#### Redis 采用单线程为什么还这么快？
- Redis 4.0 版本之前
  - 首先，一个重要的原因是，Redis 的大部分操作都在内存中完成，并且采用了高效的数据结构，比如哈希表和跳表。
  - 其次，因为是单线程模型避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
  - 最后，也是最重要的一点， Redis 采用了 I/O 多路复用机制处理大量的客户端 Socket 请求，
    - 这让 Redis 可以高效地进行网络通信，因为基于非阻塞的 I/O 模型，就意味着 I/O 的读写流程不再阻塞。
- Redis 4.0 版本之后
  - Redis 添加了多线程的支持，但这时的多线程主要体现在大数据的异步删除功能上，例如 unlink key、flushdb async、flushall async 等。
- Redis 6.0 版本之后
  - 因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上，
  - 所以为了提高网络请求处理的并行度，Redis 6.0 对于网络请求采用多线程来处理。
  - 但是对于读写命令，Redis 仍然使用单线程来处理。
#### 追问：Redis的多路IO复用机制是什么？工作原理是什么？
#### 事件驱动
- redis本身是个事件驱动程序，通过监听文件事件和时间事件来完成相应的功能。
    - 其中文件事件其实就是对socket的抽象，把一个个socket事件抽象成文件事件
    - 基于Reactor模式开发了自己的网络事件处理器。
#### socket通信简介
- 发送方
    - 发送方向socket的缓冲区发送数据，等待系统从缓冲区把数据取走
    - 通过网卡把数据发出去
- 接收方
    - 接收方的网卡在收到数据之后，会把数据copy到socket的缓冲区
    - 等待应用程序来取
- copy数据的开销
    - 因为涉及到系统调用，整个过程可以发现一份数据需要先从用户态拷贝到内核态的socket
    - 然后又要从内核态的socket拷贝到用户态的进程中去，这就是数据拷贝的开销。
- 数据传输
    - 建立TCP连接
    - 通过四元组唯一定义：ip（client）+ port（client）+ip（server）+port（server）
        - 单机可以有N个ip，因此最大并发为N * 65536
    - 操作系统会为每个socket建立一个fd句柄，
        - 指向我们创建的socket对象，其包含缓冲区、进程的等待队列
    - 对于一个创建socket的进程来说，如果数据没到达，那么他会卡在recv处，
        - 这个进程会挂在socket对象的等待队列中
        - 对cpu来说，这个进程就是阻塞的，它其实不占有cpu，它在等待数据的到来。
    - 当数据到来时，
        - 网卡会告诉cpu，cpu执行中断程序，把网卡的数据copy到对应的socket的缓冲区中
        - 然后唤醒等待队列中的进程，把这个进程重新放回运行队列中
        - 当这个进程被cpu运行的时候，它就可以执行最后的读取操作了
#### Reactor模式（Redis采用）
- Reactor模式下主程序只负责监听文件描述符上是否有事件发生，工作线程处理文件描述符的读写
- 当某个socket发生可读可写的事件后，主程序会通知工作程序，然后工作线程真正从socket里面读取数据和写入数据
    - 通过Reactor模式，我们只需要把事件和事件对应的handler（callback func），注册到Reactor中就行了
    - 好处：就是主程序可以扛并发，不阻塞，非常的快；事件可以通过队列的方式等待被工作程序执行
- 实现: IO多路复用器，有select、poll、evport、kqueue、epoll
- epoll的做法
    - 内核的socket不在和用户的进程绑定了，而是和epoll绑定，
    - 当socket的数据到来时，中断程序就会给epoll的一个就绪对列添加对应socket fd，
    - 这个队列里都是有数据的socket，然后和epoll关联的进程也会被唤醒，
    - 当cpu运行进程的时候，就可以直接从epoll的就绪队列中获取有事件的socket，执行接下来的读。
    - 整个流程下来，可以发现用户程序不用无脑遍历，内核也不用遍历（select和poll的模式中内核需要遍历），通过中断做到"谁有数据处理谁"的高效表现。
##### 6.0以前的单线程执行过程
- 一个客户端向redis发起set key value的命令，这时候会向socket缓冲区写入这样的命令请求，
- 当Reactor监听到对应的socket缓冲区有数据了，那么此时的socket是可读的，Reactor就会触发读事件，
- 通过事先注入的ReadCallback回调函数来完成命令的解析、命令的执行。
- 当socket的缓冲区有足够的空间可以被写，那么对应的Reactor就会产生可写事件，此时就会执行事先注入的WriteCallback回调函数。
- 当发起的set key value执行完毕后，此时工作程序会向socket缓冲区中写入OK，最后客户端会从socket缓冲区中取走写入的OK。
- 在redis中不管是ReadCallback，还是WriteCallback，它们都是一个线程完成的，如果它们同时到达那么也得排队，这就是redis6.0之前的默认模式，也是最广为流传的单线程redis。
- 注意：整个流程下来可以发现Reactor主程序非常快，因为它不需要执行真正的读写，剩下的都是工作程序干的事：IO的读写、命令的解析、命令的执行、结果的返回.
- 单线程的问题
    - 当执行删除某个很大的集合或者hash的时候会很耗时（不是连续内存），那么单线程的表现就是其他还在排队的命令就得等待
#### 4.0开始的异步线程
- redis4.0针对大key删除的情况，出了个异步线程。
- 用unlink代替del去执行删除，这样当我们unlink的时候，redis会检测当删除的key是否需要放到异步线程去执行（比如集合的数量超过64个）
- 如果value足够大，那么就会放到异步线程里去处理，不会影响主线程。
- 同样的还有flushall、flushdb都支持异步模式
#### 多线程的原理
- 注意1：redis的多线程仅仅只是处理socket IO读写（性能瓶颈）是多个线程，真正去运行指令还是一个线程去执行的。
- 注意2：多线程模式下，每个IO线程负责处理自己的队列，不会互相干扰，IO线程要么同时在读，要么同时在写，不会同时读或写
- 注意3：主线程只会在所有的子线程的任务处理完毕之后，才会尝试再次分配任务。同时最终的命令执行还是由主线程自己来完成，整个过程不涉及到锁。
- 主要原理
    - redis server通过EventLoop来监听客户端的请求，
        - 当一个请求到来时，主线程并不会立马解析执行，而是把它放到全局读队列clients_pending_read中，并给每个client打上CLIENT_PENDING_READ标识。
    - 然后主线程通过RR（Round-robin）策略把所有任务分配给I/O线程和主线程自己。
    - 每个线程（包括主线程和子线程）根据分配到的任务
        - 通过client的CLIENT_PENDING_READ标识只做请求参数的读取和解析（这里并不执行命令）。
    - 主线程会忙轮询等待所有的IO线程执行完，
        - 每个IO线程都会维护一个本地的队列io_threads_list和本地的原子计数器io_threads_pending，
        - 线程之间的任务是隔离的，不会重叠，当IO线程完成任务之后，io_threads_pending[index] = 0，
        - 当所有的io_threads_pending都是0的时候，就是任务执行完毕之时。
    - 当所有read执行完毕之后，主线程通过遍历clients_pending_read队列，来执行真正的exec动作。
    - 在完成命令的读取、解析、执行之后，就要把结果响应给客户端了。主线程会把需要响应的client加入到全局的clients_pending_write队列中。
    - 主线程遍历clients_pending_write队列，再通过RR（Round-robin）策略把所有任务分给I/O线程和主线程，让它们将数据回写给客户端。


### Redis 如何实现数据不丢失？（数据持久化，高可用问题）
- AOF 日志（Append Only File，文件追加方式）：记录所有的操作命令，并以文本的形式追加到文件中。
  - Redis是写后日志（不同于Mysql的写前日志），即先执行命令，把数据写入内存，然后再记录日志到文件
  - Reids 为什么先执行命令，在把数据写入日志呢？
    - 因为 ，Redis 在写入日志之前，不对命令进行语法检查；
    - 所以，只记录执行成功的命令，避免了出现记录错误命令的情况；
    - 并且，在命令执行完之后再记录，不会阻塞当前的写操作。
    - 这样做也会带来风险
      - 数据可能会丢失： 如果 Redis 刚执行完命令，此时发生故障宕机，会导致这条命令存在丢失的风险。
      - 可能阻塞其他操作： 虽然 AOF 是写后日志，避免阻塞当前命令的执行，但因为 AOF 日志也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。
- RDB 快照（Redis DataBase）：将某一个时刻的内存数据，以二进制的方式写入磁盘。
  - AOF缺点： AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，一旦日志非常多，势必会造成 Redis 的恢复操作缓慢
  - RDB 内存快照方式，即可以保证可靠性，又能在宕机时实现快速恢复。
  - RDB 做快照时会阻塞线程吗？
    - save 命令在主线程中执行，会导致阻塞。
    - bgsave 命令则会创建一个子进程，用于写入 RDB 文件的操作，避免了对主线程的阻塞，（默认配置）
  - RDB 做快照的时候数据能修改吗？（非常重要），答案是可以修改，这部分修改会丢失
    - 如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响；
    - 如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。
- （Redis 4.0 后）混合持久化方式：Redis 4.0 新增了混合持久化的方式，集成了 RDB 和 AOF 的优点。(如何保证执行快照期间数据可修改)
  - 数据以 RDB 的方式写入文件，再将后续的操作命令以 AOF 的格式存入文件，既保证了 Redis 重启速度，又降低数据丢失风险。

### Redis 如何实现服务高可用？
- 主从同步 (主从复制)
  - 一主多从的模式，这样我们就可以对 Redis 做读写分离了
  - 问题：当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复
- Redis Sentinel（哨兵模式）
  - 可以监控主从服务器，并且提供自动容灾恢复的功能
- （Redis 3.0）Redis Cluster（集群，多主多从）
  - 分布式去中心化的运行模式，将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。
  - 采用哈希槽（Hash Slot，16384个），来处理数据和实例之间的映射关系
  - 分配槽位，平均分配和手动分配两种


### Redis pipeline为什么能提升大批量数据插入的效率
- 普通命令经历四个阶段：1）发送命令－〉（2）命令排队－〉（3）命令执行－〉（4）返回结果
  - pipeline管道机制，它能将一组Redis命令进行组装，通过一次RTT传输给Redis，并将这组Redis命令的执行结果按顺序返回给客户端
- Pipeline不能保证原子性。 
  - Pipeline模式只是将客户端发送命令的方式改为发送批量命令，而服务端在处理批量命令的数据流时，
  - 仍然是解析出多个单命令并按顺序执行，各个命令相互独立，即服务端仍有可能在该过程中执行其他客户端的命令。如需保证原子性，请使用事务或Lua脚本。
- 若Pipeline执行过程中发生错误，不支持回滚。 
  - Pipeline没有事务的特性，如待执行命令的前后存在依赖关系，请勿使用Pipeline。
- 由于服务端以及部分客户端存在缓存区限制，建议单次Pipeline中不要使用过多的命令。 
- Pipeline的本质为客户端与服务端的交互模式，与服务端的架构无关，因此集群架构代理模式、集群架构直连模式以及读写分离架构实例均支持Pipeline。


### redis过期策略
1. 定时策略：在设置key的过期时间的同时，为该key创建一个定时器，让定时器在key的过期时间来临时，对key进行删除
- 优点：保证内存被尽快释放，减少无效的缓存暂用内存
- 缺点：若过期key很多，删除这些key会占用很多的CPU时间；定时器很多，影响性能，一般不选这种
2. 惰性策略：key过期的时候不删除，每次从数据库获取key的时候去检查是否过期，若过期，则删除，返回null
- 优点：删除操作只发生在从数据库取出key的时候发生，而且只删除当前key，所以对CPU时间的占用是比较少的
- 缺点：若大量的key在超出超时时间后，很久一段时间内，都没有被获取过，此时的无效缓存是永久暂用在内存中的，那么可能发生内存泄露
3. 定期策略：每隔一段时间对设置了缓存时间的key进行检测，如果可以已经失效，则从内存中删除，如果未失效，则不作任何处理（随机取key，不遍历所有key）
- 优点：通过限制删除操作的时长和频率，来减少删除操作对CPU时间的占用--处理"定时删除"的缺点；定期删除过期key--处理"惰性删除"的缺点
- 缺点：在内存友好方面，不如"定时删除"，因为是随机遍历一些key，因此存在部分key过期，但遍历key时，没有被遍历到，过期的key仍在内存中。在CPU时间友好方面，不如"惰性删除"，定期删除也会暂用CPU性能消耗。

### 缓存和数据库一致性怎么解决（https://xie.infoq.cn/article/47241d099404a1565e168fad4）
#### 前提讨论（缓存用删除而不是更新，防止多线程竞争）
1. 先删除缓存，再更新数据库
    - 可能导致数据不一致，同时有一个请求 A 进行更新操作，另一个请求 B进行查询操作。那么会出现如下情形:
（1）请求 A 进行写操作，删除缓存
（2）请求 B 查询发现缓存不存在
（3）请求 B 去数据库查询得到旧值
（4）请求 B 将旧值写入缓存
（5）请求 A 将新值写入数据库
    - 此时缓存中是旧值，若不采用给缓存设置过期时间策略，该数据永远都是脏数据
2. 先更新数据库，再删除缓存
    - 也可能导致数据不一致，一个请求 A 做查询操作，一个请求 B做更新操作，那么会有如下情形产生
（1）缓存刚好失效
（2）请求 A 查询数据库，得一个旧值
（3）请求 B 将新值写入数据库
（4）请求 B 删除缓存
（5）请求 A 将查到的旧值写入缓存
    - 一般不会发生，理由是（3）写数据库更耗时，大多数情况下采用这种
#### 解决方案
1. 缓存延时双删：先淘汰缓存，再更新数据库，等1s后再次淘汰缓存（第二次可以异步以增加吞吐量）
   - 不能完全解决不一致的问题
   - 在线程sleep期间，别的线程又更新了缓存，第二次删除就把新的缓存删掉了（其实不应该删）
2. 重试机制：解决缓存删除失败的情况（延迟双删第二次可能会失败）
   - 缓存删除失败后，把请求放入MQ，再消费MQ重试之
   - 非侵入的代码，订阅binlog，做重试删除缓存


### bitmap可以做什么
- 优势：存储海量数据，一个用户占用1bit，1亿个用户，占用12.5MB（1B = 8 bits）
- bitmap是通过一个bit数组来存储特定数据的一种数据结构，最大可以存放2的32次方（512MB）
  - 可以用于排序，如1 2 3 5 7 可以用1B的数据，8位分别代表0-7，有则置1，最后遍历即可 
  - 员工打卡记录，SETBIT key offset value结合GETBIT命令查看某人是否打卡，结合BITCOUNT查看某天打卡总人数
  - 构建布隆过滤器


### 分布式限流器怎么实现
1. 令牌桶：一定大小的桶，每隔一段时间往里面放令牌（直到满），每个请求拿k个，拿完之后后面的请求拒绝
   - Google的Guava
2. 漏斗桶：通过一个 FIFO （First in first out）的队列（有界）实现，如果请求堆积满了队列，就会触发丢弃策略。消费者以一定的速率消化这些请求
3. 固定时间窗口（Fixed window）：将时间切分成若干个时间片，每个时间片内固定处理若干个请求。
   - 假设n秒内最多处理b个请求，那么每隔n秒将计数器重置为b。请求到来时，如果计数器值足够，则扣除并请求通过，不够则触发拒绝策略。
   - 缺陷：请求都在时间窗口的开头被迅速消耗，剩下的时间不处理任何请求
4. 滑动日志（Sliding Log）：滑动日志根据缓存之前接受请求对应的时间戳，与当前请求的时间戳进行计算，控制速率。这样可以严格限制请求速率。
   - 假设n秒内最多处理b个请求。那么会最多缓存 b 个通过的请求与对应的时间戳，假设这个缓存集合为B。
   - 每当有请求到来时，从B中删除掉n秒前的所有请求，查看集合是否满了，如果没满，则通过请求，并放入集合，如果满了就触发拒绝策略。
5. 滑动窗口（滑动日志 + 固定窗口）：假设n秒内最多处理b个请求。
   - 我们可以将n秒切分成每个大小为m毫秒得时间片，只有最新的时间片内缓存请求和时间戳，之前的时间片内只保留一个请求量的数字。这样可以大大优化存储，小幅度增加计算量。

#### 分布式限流
在redis上配置限流器，每个节点收到来自上游的请求后直接请求数据库，然后数据库根据限流器判断是否处理这个请求，最后返回给节点相关信息。如果请求量大，redis负载较高
1. 在节点上积攒够一定的请求量N后再去请求中心限流器，这样节点对中心化数据库的请求频次会降低为1/N。
   - 缺点：请求积攒阶段这些请求就无法决定是否被处理，这样也会造成一定的延迟增加。并且如果请求十分不均匀，在积攒阶段迟迟攒不到N个，即使设置了积攒超时也会大大增加延迟
2. 认为负载均衡器会将流量十分均匀的分布在各个节点上，这样本地限流器的配置就等于全局限流器的配置除以节点数量
   - 缺点：对中心化数据库的压力更小，但误差也更大，负载均衡器并不能保证流量会十分均匀地打到各个节点上，其次中心化数据库也可能对活着的节点数量统计不准确
3. 每个节点初始时请求中心限流器N个令牌，当N个令牌都消耗完了再去数据库请求N个
   - 只针对令牌算法，有一定的误差


### 布隆过滤器在Redis中的应用（适合百万级别手机号和url的判断）
一个大的bit数组，几个hash函数，对健key，通过几个hash函数，计算得第k位是否为1，如果判断结果都为否，则肯定不存在；判断存在则只是可能存在
适用于：邮件&网站黑名单，新闻推荐去重，恶意攻击导致的缓存穿透，查询加速（缓存不存在再访问磁盘）


### 什么是缓存雪崩、缓存击穿、缓存穿透和缓存并发问题？
1. 雪崩
- 如果缓在某一个时刻出现大规模的key失效，那么就会导致大量的请求打在了数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。
  - 这时候如果运维马上又重启数据库，马上又会有新的流量把数据库打死。这就是缓存雪崩。
- 原因：redis宕机，采用相同的过期时间
- 解决：1. 过期时间不是同一个  2. 分级缓存，每一级缓存过期时间不同  3. 热点数据缓存永不过期（不设置过期时间或借助value延时） 4. 主从哨兵或集群保证高可用
2. 击穿
- 缓存击穿是某个热点的key失效，大并发集中对其进行请求，就会造成大量请求读缓存没读到数据，从而导致高并发访问数据库，引起数据库压力剧增。这种现象就叫做缓存击穿。
- 解决：1. 永不过期  2. 缓存失效后，通过互斥锁或队列控制数据写缓存的线程数量，如某个key只 允许一个线程访问，其他阻塞等待
3. 穿透
- 指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍。
  - 如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至导致数据库承受不住而宕机崩溃。
- 解决：1. 布隆过滤器：数据库中的所有key存放在布隆过滤器中，不存在直接返回  2. 无效的key存放入redis中，value为null（不能解决随机key问题）
4. 缓存并发
- 假设在缓存失效的同时，出现多个客户端并发请求获取同一个 key 的情况，此时因为 key 已经过期了，
  - 所有请求在缓存数据库中查询 key 不命中，那么所有请求就会到数据库中去查询，然后当查询到数据之后，所有请求再重复将查询到的数据更新到缓存中。
- 不仅会增加数据库的压力，还会因为反复更新缓存而占用缓存资源，这就叫缓存并发
- 解决的主要步骤
  1. 没有读取到数据，那么就在 Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态；
  2. 锁定状态设置成功，表示已经锁定成功，这时候请求从数据库中读取数据，然后更新缓存，最后再将数据返回给客户端；
  3. 锁定状态没有设置成功，表示这个状态位已经被其他请求锁定，此时这个请求会等待一段时间再重新发起数据查询；
- 能保证在同一时间只能有一个请求来查询数据库并更新缓存系统，其他请求只能等待重新发起查询，从而解决缓存并发的问题
#### 怎么设计一个动态缓存热点数据的策略？
- 通过判断数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据
- 缺点：与业务耦合重，迭代不方便
#### 怎么设计一个缓存操作与业务分离的架构？
- 通过 MySQL Binlog + Canal + MQ 的方式
- 通过使用 Canal 组件来获读取最新的 Binlog 日志数据，
- 然后解析日志数据，并通过事先约定好的数据格式，发送到 MQ 消息队列中，
- 最后再由应用系统将 MQ 中的数据更新到 Redis 中，完成缓存操作和业务代码之间的解耦


### 跳表怎么实现的 ，为何不用红黑树，跳表有何优势，时间复杂度是多少
不用红黑树：1. 复杂度一样，实现更简单  2. zrange更方便  3. 更少的内存占用（可以少一些层） 
实现：层（随机生成1-32的数，数越大，出现几率越小），前进指针，后退指针，跨度（记录两个节点之间的距离），分值和对象
时间复杂度：插入、删除平均为log(n)，最坏是O(n)（此时退化成单链表）

### 为啥是跳表，不是平衡树？
- 参考：https://zhuanlan.zhihu.com/p/421592153
- 平衡树：平衡树是一种自平衡的二叉搜索树，其中任何节点的两个子树的高度差不超过1。
- 复杂度一样，而且实现起来更简单。
- 从内存占用上来比较，跳表比平衡树更灵活一些。
  - 平衡树每个节点包含 2 个指针（分别指向左右子树），
  - 跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。
    - 如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。
- 在做范围查找（ZRANGE或ZREVRANGE）的时候，跳表比平衡树操作要简单。（且缓存局部性性更好）
  - 在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。
  - 在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。
- 在并发环境下（复杂度也更低）
  - 平衡树在插入和删除的时候可能需要做一些rebalance的操作，这样的操作可能会涉及到整个树的其他部分，
  - skiplist的操作显然更加局部性一些，锁需要盯住的节点更少，因此在这样的情况下性能好一些。
#### 跳表的原理简述
- 数据结构
  - 索引有forward指针数组，每个节点的数组长度不一样，该数组的第i项表示第n层的索引
  - 最高层数为32，此时有2^64个节点
- 空间复杂度
  - 共n个元素，第一层索引n/2，第二次n/4，... 最后一级2个节点
  - 索引空间的总和为n-2，空间复杂度O(n)
  - 如果每3个元素取一个，和为n/2；每4个元素取一个，和为n/3
- 查找，从上往下找，每一层遍历m个节点，共log(n)层，时间复杂度m*log(n)
  - 可以证明在k层时，a < target < b时，遍历下一层，而下一层在x和y之间的值不超过3个，则m=3
- 插入
  - 先在O(logn)的时间复杂度找到要插入和删除的节点位置
  - 再使用随机算法（概率p=0.25，即1/4的概率增加1层，1/16的概率增加2层。。。），选择把待插入结点放到哪些层的索引中
    - 避免了某两个索引之间插入太多的节点，查询效率退化
    - 无需像平衡树一样，每次调整大量节点
  - 注意层数可能会上升
- 删除
  - 找到对应节点，删除即可
  - 注意层数可能会下降
  

### sds怎么实现的
1. len记录长度，free未用长度和buf[]存放字符，尾部也要加\0
2. 杜绝缓冲区溢出：先检查SDS的空间是否满足修改的需求，若不满足，则API会自动将SDS的空间扩展以至于能够放下src
3. 减少修改字符串时带来的内存重分配次数：
- C语言在字符串增长操作前，要先扩容，否则会发生缓冲区溢出字符串缩长操作前，要先释放空间，否则会内存泄露
- 空间预分配：在对SDS增长时，检查free够不够用，不够用触发扩容若增长后len小于1M，则分配free = len的额外空间若len 大于1M，则分配free = 1M的额外空间
- 惰性空间释放：对SDS缩短时，把空闲空间记录在free中，并不释放
4. 二进制安全：
- C字符串存在二进制安全的问题，它职能保存文本数据，而不能保存像图片、音频、视频压缩文件等二进制数据，因为遇到'\0'就是一个结束了的C字符串。
- 而SDS的API都是二进制安全的，所有API以处理二进制的方式来处理SDS存放的buf数组里的数据，
  - 程序不会对其中的数据做任何限制、过滤、或者转义，数据在写入时是怎么样的，被读取时就是什么样。
  - 这也是将SDS的buf数组叫做字节数组的原因——Redis不是用这个数组来保存字符，而使用它来直接保存二进制数据。


### Redis如何做分布式锁以及和zk锁的区别
#### Redis的锁
1. setNX（set if not exist）或set key value nx px 2000，其中px用来指定过期时间。
2. redlock解法：在大半的节点获取分布式锁，如果获取时间小于锁过期时间，代表获取锁成功。
   - 否则创建失败，依次删除锁（防止加锁请求发送成功，结果返回丢失）。如果别人已经建立了，就不断轮询获取锁
3. 开源框架Redission
 - 所有指令通过Lua脚本执行，Redis执行Lua脚本是原子的
 - 利用WatchDog概念，会在获取锁之后，每隔1/3（如10s）的过期时间就把锁的过期时间延长（每过10s过期时间延长至30s）。
 - 比不设置超时时间的好处是当宕机之后，看门狗消失，30s后锁过期，其他进程就能再获取锁了
### zk的一致性
- zk不保证强一致性，只保证顺序一致，弱于强一致，比最终一致强得多
- zk的写是线性一致（强一致）的，换句话说，每次写入将在客户端发出请求和接收相应响应之间的某个时间点自动生效。
- zk的读不需要仲裁，直接返回，可能会读到旧数据

#### zk的锁
1. 每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下
2. 创建成功后，获取/lock下所有临时节点，判断当前线程创建的节点是否是序号最小的
3. 最小的线程获取锁成功，其他线程对前一个节点添加事件监听，锁释放后会对下一个节点进行唤醒，然后重复2

#### 区别
1. 服务端性能
- zk基于Zab协议，需要一半的节点ACK，才算写入成功，吞吐量低
- Redis只写master就算成功，吞吐量高
2. 客户端性能
- Zk由于有通知机制，获取锁的过程，添加一个监听器。避免了轮询，性能消耗小
- Redis并没有通知机制，只能使用类似CAS的轮询，对客户端压力较大
3. 可靠性
- redis追求吞吐量，可靠性上稍逊，即使用了Redlock，在极端情况下也不能保证一致性
- zk有zab协议控制数据的一致性


### redlock的不可靠
1. 用不可靠的时钟打破 Redlock
    - client1 从 ABC 三个节点处申请到锁，DE由于网络原因请求没有到达
    - C节点的时钟往前推了，导致 lock 过期
    - client2 在CDE处获得了锁，AB由于网络原因请求未到达
    - 此时 client1 和 client2 都获得了锁

2. 进程 Pause 时而不是时钟不可靠时会发生的问题：
    - client1 从 ABCDE 处获得了锁
    - 当获得锁的 response 还没到达 client1 时 client1 进入 GC 停顿
    - 停顿期间锁已经过期了
    - client2 在 ABCDE 处获得了锁
    - client1 GC 完成收到了获得锁的 response，此时两个 client 又拿到了同一把锁


### 如何解决redis热点key问题
自己统计，提前预热等，加入二级缓存或集群备份key解决

### Redis有一批key同时过期，会影响其他key的读写效率吗？为什么？
- 会，原因是redis清理过期键的操作时
  1. 需要遍历整个数据库
  2. 删除操作可能会导致内存碎片的产生，影响其他键的读写效率

### Redis为什么快，为什么能达到10w qps
- 基于内存操作
- 单线程，无线程切换开销
- IO多路复用技术
- 单线程处理网络请求（6.0新增多线程）
- 使用管道能增加qps
- 其他业务会再fork新进程处理，如rehash，写日志等 

#### Hash的扩容流程？渐进式Rehash的时候会影响主流程吗？
- 见 https://www.processon.com/mindmap/634199f41efad41678790a2a

### Redis 是否可以作为分布式锁？
- 问你用 Redis 实现分布式锁会存在哪些问题
- 为什么 Redis 会采用 AP 模型等
#### 说明现实存在的问题
- 一般使用 setnx 方法，通过 Redis 实现锁和超时时间来控制锁的失效时间。
- 但是在极端的情况下，当 Reids 主节点挂掉，但锁还没有同步到从节点时，根据哨兵机制，从就变成了主，继续提供服务
- 这时，另外的线程可以再来请求锁，此时就会出现两个线程拿到了锁的情况。

#### 回归理论的指导
- 根据对 CAP 理论（怎么权衡）的理解，
- Redis 的设计模型是 AP 模型，而分布式锁是一个 CP 场景，
- 那么很明显，将 Redis 这种 AP 模型的架构应用于 CP 的场景，在底层的技术选型上就是错误的。

#### 扩展到知识体系
- Redis 属于分布式存储系统，你的头脑里就要有对分布式存储系统领域的知识体系。
- 思考它的数据存储、数据分布、数据复制，以及数据一致性都是怎么做的，用了哪些技术来实现，为什么要做这样的技术或算法选型。
- 你要学会从多维度、多角度去对比、分析同一分布式问题的不同方法，然后综合权衡各种方法的优缺点，最终形成自己的技术认知和技术判断力。

#### 有技术的判断力
- 比如通过 Redis，你能想到目前分布式缓存系统的发展现状以及技术实现，如果让你造一个“Redis”出来，你会考虑哪些问题等。
- 虽然在实际工作中不推荐重复“造轮子”，但在面试中要表现出自己具备“造轮子”的能力。

#### redis有事务吗？是怎么实现的？
- 见 https://www.processon.com/mindmap/634199f41efad41678790a2a

### redis的集群方案有哪些，与单节点的区别
- 主从模式
- Redis Sentinel（哨兵）
  - Redis Sentinel是一种高可用性解决方案，它通过监视Redis实例并在主实例故障时自动进行故障转移来提供高可用性
- Redis Cluster（共3种）
  - Redis Cluster是一种分布式解决方案，它将数据分片并将其存储在多个Redis实例中，从而提高了性能和可伸缩性。
  - Redis Cluster还提供了自动分片和故障转移功能，以确保数据的高可用性和可靠性。
- 与单节点相比，Redis Sentinel和Redis Cluster都提供了更高的可用性和可伸缩性，但它们也需要更多的配置和管理工作。
  - Redis Sentinel适用于需要高可用性但不需要分布式的场景
  - 而Redis Cluster适用于需要高可用性和可伸缩性的场景。
#### 优缺点
- 主从
  - 优点： 
    - master能自动将数据同步到slave，可以进行读写分离，分担master的读压力
    - master、slave之间的同步是以非阻塞的方式进行的，同步期间，客户端仍然可以提交查询或更新请求
  - 缺点 
    - 不具备自动容错与恢复功能，master或slave的宕机都可能导致客户端请求失败，需要等待机器重启或手动切换客户端IP才能恢复
    - master宕机，如果宕机前数据没有同步完，则切换IP后会存在数据不一致的问题
    - 难以支持在线扩容，Redis的容量受限于单机配置
- 哨兵
  - 优点
    - 哨兵模式基于主从复制模式，所以主从复制模式有的优点，哨兵模式也有
    - master挂掉可以自动进行切换，系统可用性更高
  - 缺点
    - 同样也继承了主从模式难以在线扩容的缺点，Redis的容量受限于单机配置
    - 需要额外的资源来启动sentinel进程，实现相对复杂一点，同时slave节点作为备份节点不提供服务
- 集群
  - 优点
    - 无中心架构，数据按照slot分布在多个节点。
    - 集群中的每个节点都是平等的关系，每个节点都保存各自的数据和整个集群的状态。
      - 每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。
    - 可线性扩展到1000多个节点，节点可动态添加或删除
    - 能够实现自动故障转移，节点之间通过gossip协议交换状态信息，用投票机制完成slave到master的角色转换
  - 缺点 
    - 客户端实现复杂，驱动要求实现Smart Client，缓存slots mapping信息并及时更新，提高了开发难度。
      - 目前仅JedisCluster相对成熟，异常处理还不完善，比如常见的“max redirect exception”
    - 节点会因为某些原因发生阻塞（阻塞时间大于 cluster-node-timeout）被判断下线，这种failover是没有必要的
    - 数据通过异步复制，不保证数据的强一致性
    - slave充当“冷备”，不能缓解读压力
    - 批量操作限制，目前只支持具有相同slot值的key执行批量操作，对mset、mget、sunion等操作支持不友好
    - key事务操作支持有线，只支持多key在同一节点的事务操作，多key分布不同节点时无法使用事务功能
    - 不支持多数据库空间，单机redis可以支持16个db，集群模式下只能使用一个，即db 0
    
### memcached和redis的区别
- Memcached 只支持简单的键值对存储，而 Redis 支持多种数据结构，如列表、集合、有序集合、哈希表等
- Memcached 使用多线程和非阻塞 I/O 复用的网络模型，而 Redis 使用单线程的 I/O 复用模型
- Memcached 使用 Slab Allocation 机制管理内存，而 Redis 使用自身设计的内存管理机制
- Redis 支持数据的备份，即 master-slave 模式的数据备份，而 Memcached 不支持数据备份
- Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 不支持数据的持久化

#### redis保持高可用的手段
- 持久化：RDS和AOF
- 哨兵
- 集群

#### zset如何避免大key问题
- zset的数据结构和空间复杂度
  - https://www.processon.com/mindmap/634199f41efad41678790a2a
- 其他的参考 redis删除大key时容易崩

### redis删除大key时容易崩，如何解决？
- 大key的问题
  - 读写大key会导致超时严重，甚至阻塞服务。
  - 如果删除大key，DEL命令可能阻塞Redis进程数十秒，使得其他请求阻塞，对应用程序和Redis集群可用性造成严重的影响。
  - 内存占用过高：当zset中元素数量过多或者元素的权重值过大时，会导致zset占用大量的内存资源，从而导致Redis的内存占用过高，影响Redis的性能和稳定性。
  - 命令执行时间过长：当zset成为一个大key时，执行zset相关的命令（如zadd、zrange等）的时间会变得很长，从而导致Redis的响应时间变慢，影响用户体验。
  - 持久化时间过长：当zset成为一个大key时，进行持久化操作（如RDB或AOF）的时间会变得很长，从而影响Redis的性能和可用性。
- 单个简单的key存储的value很大
  - 对象需要每次都整存整取
    - 可以尝试将对象分拆成几个key-value，使用multiGet获取值，这样分拆的意义在于分拆单次操作的压力，将操作压力平摊到多个redis实例中，降低对单个redis的IO影响；
  - 对象每次只需要存取部分数据
    - 可以像第一种做法一样，分拆成几个key-value，也可以将这个存储在一个hash中，每个field代表一个具体的属性，使用hget,hmget来获取部分的value，使用hset，hmset来更新部分属性
  - hash，set，zset，list 中存储过多的元素
    - 类似于场景一种的第一个做法，可以将这些元素分拆。
    - 以hash为例，原先的正常存取流程是hget(hashKey, field) ; hset(hashKey, field, value)
    - 现在，固定一个桶的数量，比如10000，每次存取的时候，先在本地计算field的hash值，模10000，确定了该field落在哪个key上。
    - set, zset, list 也可以类似上述做法
- 解决（如何优雅地删除Redis大键）
  - 内存空间复杂性处理耗时都非常小，测试 del 200MB String键耗时约1毫秒，而删除一个含有1kw个字段的Hash键，却会阻塞Redis进程数十秒
  - 直接删除大Key的风险 
    - DEL命令在删除单个集合类型的Key时，命令的时间复杂度是O(M)，其中M是集合类型Key包含的元素个数。
    - 生产环境中遇到过多次因业务删除大Key，导致Redis阻塞（单线程模型，该删除不完成，无法处理后续命令），出现故障切换和应用程序雪崩的故障。
    - 测试删除集合类型大Key耗时，一般每秒可清理100w~数百w个元素; 如果数千w个元素的大Key时，会导致Redis阻塞上10秒。
    - 可能导致集群判断Redis已经故障，出现故障切换；或应用程序出现雪崩的情况。
  - 如何优雅地删除各类大Key
    - Redis2.8版本开始支持SCAN命令，通过m次时间复杂度为O(1)的方式，遍历包含n个元素的大key。避免单个O(n)的大命令，导致Redis阻塞
    - 字符串：直接删除，对于string类型使用del命令不会产生阻塞，属于占用空间大的类型
    - Hash Key：hscan获取，hdel删除
    - Set Key：sscan获取，srem删除
    - List Key：ltrim渐进删除
    - Sorted set key：1. zscan获取，zrem删除； 2. zremrangebyrank渐进删除（时间复杂度O(log(N)）
    - Redis Lazy Free：4.0新特性，本质就是把某些cost(主要时间复制度，占用主线程cpu时间片)较高删除操作，从redis主线程剥离，让bio子线程来处理，极大地减少主线阻塞时间。从而减少删除导致性能和稳定性问题。
      - 采用UNLINK命令（del的非阻塞版本），如果集合键的元素个数大于64个，会把真正的内存释放操作，给单独的bio来操作
      - Lazy Free还能应用于被动删除
        - lazyfree-lazy-eviction：redis内存使用达到maxmeory，并设置有淘汰策略时；在被动淘汰键时，是否采用lazy free机制
        - lazyfree-lazy-expire：设置有TTL的键，达到过期后，被redis清理删除时是否采用lazy free机制
        - lazyfree-lazy-server-del：有些指令在处理已存在的键时，会带有一个隐式的DEL键的操作
          - 如rename命令，当目标键已存在,redis会先删除目标键，如果这些目标键是一个big key,那就会引入阻塞删除的性能问题
        - slave-lazy-flush：slave进行全量数据同步，slave在加载master的RDB文件前，会运行flushall来清理自己的数据场景，参数设置决定是否采用异步flush机制

### redis过期策略
- 定期删除
  - 每隔100ms就随机抽取一些设置了过期时间的key，检查是否过期，如果过期就删除
- 惰性删除
  - 获取某个key的时候，redis会检查一下，这个key如果设置了过期时间并且已经过期了，此时就会删除，不会给你返回任何东西

### 内存淘汰机制？
- 4.0 版本之前有 6 种策略，4.0 增加了 2种，主要新增了LFU算法（对使用次数排序）
- 默认为no-eviction
- volatile-lru	从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
- volatile-lfu	从已设置过期时间的数据集中挑选最不经常使用的数据淘汰
- volatile-ttl	从已设置过期时间的数据集中挑选将要过期的数据淘汰
- volatile-random	从已设置过期时间的数据集中挑选任意数据淘汰
- allkeys-lru	当内存不足写入新数据时淘汰最近最少使用的Key
- allkeys-random	当内存不足写入新数据时随机选择key淘汰
- allkeys-lfu	当内存不足写入新数据时移除最不经常使用的Key
- no-eviction	当内存不足写入新数据时，写入操作会报错，同时不删除数据
 

### 如何保证缓存一致性
- 先更新数据库，再删缓存

### 为什么redis的lua脚本是原子性的
- Redis 执行 Lua 脚本时可以简单的认为仅仅只是把命令打包执行了，命令还是依次执行的，只不过在 Lua 脚本执行时是阻塞的，避免了其他指令的干扰。
  - 采用一个伪客户端来执行
- 一个lua脚本是一个命令
  - 但执行到一半宕机，结果不会存储，相当于此脚本未被执行

### 延迟双删是解决什么问题的？是怎么做的？
- 解决数据删除时，缓存和数据库一致性问题的
- 先更新数据库，然后删缓存

### redis的协议
- 基于TCP的？？？

#### 排查redis的大分片占用内存比例过高
- dump下来rdb文件，分析下key的分布

#### 分布式锁在Redis主从部署的情况下，主从节点延时怎么办
- 使用 Redis Sentinel：
  - Redis Sentinel 是 Redis 官方提供的一种高可用性解决方案，它可以监控 Redis 主从节点的状态，并在主节点故障时自动切换到从节点。
  - 使用 Redis Sentinel 可以保证分布式锁的高可用性和可靠性。
- 使用 Redlock 算法：Redlock 算法是一种基于多个 Redis 实例的分布式锁算法，它可以在多个 Redis 实例之间协调锁的获取和释放。
  - Redlock 算法可以保证在大多数 Redis 实例正常运行的情况下，分布式锁的可靠性和高可用性。 
- 使用 ZooKeeper：ZooKeeper 是一个分布式协调服务，它可以用于实现分布式锁。
  - 使用 ZooKeeper 可以保证分布式锁的可靠性和高可用性，但是需要额外的开销和维护成本。

### 单redis节点加锁
- Redis节点上，即使Redis通过sentinel保证高可用，如果这个master节点由于某些原因发生了主从切换，那么就会出现锁丢失的情况： 
  - 在Redis的master节点上拿到了锁；
  - 但是这个加锁的key还没有同步到slave节点；
  - master故障，发生故障转移，slave节点升级为master节点；
  - 导致锁丢失。
